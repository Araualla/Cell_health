{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiles\n",
    "This notebook computes threshold-based profiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run notebook_imports\n",
    "%run notebooks/matplotlib_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd party libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from collections import defaultdict\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from os import makedirs\n",
    "from os.path import exists\n",
    "from functools import reduce\n",
    "from scipy.stats import kruskal\n",
    "from os import listdir, mkdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import PartialPca\n",
    "from utilities.paths import path\n",
    "from utilities.constants import column_order, index_order, CONC, TREAT\n",
    "from utilities.data_cleaning import label_data, format_column_name, normalise_data, clean_data\n",
    "from utilities.thresholds import _THRESHOLD_ABOVE, _THRESHOLD_BELOW, threshold_dict,extract_threshold_percentile, extract_from_replicate\n",
    "from utilities.plots import plot_heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`_TRHESHOLD` can be set to either `_THRESHOLD_BELOW` or `_THRESHOLD_ABOVE`. Some parts of this notebook consider the percentage of cells going below (or above the) thresholds, let's call them *\"one-sided\"*. This constant value modifies the behaviour of those parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_THRESHOLD = _THRESHOLD_BELOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "whether to save figures, and show plots in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_figures = True\n",
    "save_figures = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_path = path.plots\n",
    "# save figures in two different paths according to\n",
    "# which kind of calculation we're doing\n",
    "if _THRESHOLD == _THRESHOLD_ABOVE:\n",
    "    figure_path_onesided = figure_path + 'threshold_above/'\n",
    "elif _THRESHOLD == _THRESHOLD_BELOW:\n",
    "    figure_path_onesided = figure_path + 'threshold_below/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = path.data_thresholds\n",
    "files_list = listdir(data_path)\n",
    "dataset_list=[filename for filename in files_list if filename.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "load both thresholds above and below. if they have not been calculated yet, do the calculation and save them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PICKLE_NAME = 'results.pkl'\n",
    "pickle_path = path.pickles\n",
    "\n",
    "try:\n",
    "    with open(pickle_path +'threshold_below-' + PICKLE_NAME,'rb') as file:\n",
    "        thresholds_below = pickle.load(file)\n",
    "    with open(pickle_path +'counts-' + PICKLE_NAME,'rb') as file:\n",
    "        counts = pickle.load(file)\n",
    "    with open(pickle_path +'normalised_count-' + PICKLE_NAME,'rb') as file:\n",
    "        normalised_counts = pickle.load(file)\n",
    "except FileNotFoundError:\n",
    "    thresholds_below = dict()\n",
    "    counts = dict()\n",
    "    normalised_counts = dict()\n",
    "    for file in tqdm(dataset_list):\n",
    "        data = pd.read_csv(data_path+file)\n",
    "        preprocessed_data, count, normalised_count = clean_data(data)\n",
    "        thresholds_below[file] = extract_from_replicate(preprocessed_data,_THRESHOLD = _THRESHOLD_BELOW)\n",
    "        counts[file] = count\n",
    "        normalised_counts[file] = normalised_count\n",
    "    with open(pickle_path +'threshold_below-' + PICKLE_NAME,'wb') as file:\n",
    "        pickle.dump(thresholds_below,file)\n",
    "    with open(pickle_path +'counts-' + PICKLE_NAME,'wb') as file:\n",
    "        pickle.dump(counts,file)\n",
    "    with open(pickle_path +'normalised_count-' + PICKLE_NAME,'wb') as file:\n",
    "        pickle.dump(normalised_counts,file)\n",
    "\n",
    "\n",
    "try:\n",
    "    with open(pickle_path +'threshold_above-' + PICKLE_NAME,'rb') as file:\n",
    "        thresholds_above = pickle.load(file)\n",
    "except FileNotFoundError:\n",
    "    thresholds_above = dict()\n",
    "    counts = dict()\n",
    "    normalised_counts = dict()\n",
    "    for file in tqdm(dataset_list):\n",
    "        data = pd.read_csv(data_path+file)\n",
    "        preprocessed_data, count, normalised_count = clean_data(data)\n",
    "        thresholds_above[file] = extract_from_replicate(preprocessed_data,_THRESHOLD = _THRESHOLD_ABOVE)\n",
    "        counts[file] = count\n",
    "        normalised_counts[file] = normalised_count\n",
    "    with open(pickle_path +'threshold_above-' + PICKLE_NAME,'wb') as file:\n",
    "        pickle.dump(thresholds_above,file)\n",
    "\n",
    "# for those parts of the notebook that only work\n",
    "# for one kind of thresholding at a time\n",
    "if _THRESHOLD == _THRESHOLD_ABOVE:\n",
    "    thresholds = thresholds_above\n",
    "elif _THRESHOLD == _THRESHOLD_BELOW:\n",
    "    thresholds = thresholds_below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limit features to those that are common to all files. Discard others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = [set(thresholds[file].keys()) for file in thresholds.keys()]\n",
    "common_features = reduce(lambda x,y: x&y, f)\n",
    "for file in thresholds.keys():\n",
    "    for feature in list(thresholds[file].keys()):\n",
    "        if feature not in common_features:\n",
    "            thresholds[file].pop(feature)\n",
    "            print(\"from\", file, \"dropped\", feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### thresholds plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this cell will determine which features are in the plot and in what order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "# 'Perimeter  (above)',\n",
    "# 'Perimeter  (below)',\n",
    "# 'Clipped Perimeter  (above)',\n",
    "# 'Clipped Perimeter  (below)',\n",
    "# 'Tperimeter  (above)',\n",
    "#  'Tperimeter  (below)',\n",
    "#  'Clipped Tperimeter  (above)',\n",
    "#  'Clipped Tperimeter  (below)',\n",
    "#  'Length  (above)',\n",
    "#  'Length  (below)',\n",
    "'Count', 'Mito Int  (above)',\n",
    "'Mito Int  (below)',  \n",
    "'Mempercell DxA (above)',\n",
    "#  'Mito Int Cell DxA (above)',\n",
    "'Mito Int Cell DxA (below)',\n",
    "#  'Mito Int Nuc DxA (above)',\n",
    "'Area Nuc (above)',\n",
    "'Form Factor (below)',\n",
    "'WMOI (above)',\n",
    "#  'Feret X  (above)',\n",
    "#  'Feret X  (below)',\n",
    "#  'Feret Y  (above)',\n",
    "#  'Feret Y  (below)',\n",
    "#  'Form Factor (above)',\n",
    "#  'Weighted Relative Moment Of Inertia (above)',\n",
    "#  'Weighted Relative Moment Of Inertia (below)',\n",
    "#  'Moment (above)',\n",
    "#  'Moment (below)',\n",
    "#  'WMOI (below)',\n",
    "#  'Area Nuc (below)',\n",
    "#  'Mem Per Nuc DxA (above)',\n",
    "#  'Mem Per Nuc DxA (below)',\n",
    "#  'Memperm (above)',\n",
    "#  'Memperm (below)',\n",
    "#  'Mempercell DxA (below)',\n",
    "'Area Cell (above)',\n",
    "#  'Area Cell (below)',\n",
    "#  'Avg Area Vac2 Per Cell (above)',\n",
    "#  'Avg Area Vac2 Per Cell (below)',\n",
    "#  'Feret X Cell (above)',\n",
    "#  'Feret X Cell (below)',\n",
    "#  'WMOI Cell (above)',\n",
    "#  'WMOI Cell (below)',\n",
    "#  'Length Cell (above)',\n",
    "#  'Length Cell (below)',\n",
    "#  'Feret Y Cell (above)',\n",
    "#  'Feret Y Cell (below)',\n",
    "#  'Moment Cell (above)',\n",
    "#  'Moment Cell (below)',\n",
    "#  'Weighted Relative Moment Inertia (above)',\n",
    "#  'Weighted Relative Moment Inertia (below)',\n",
    "#  'Clippedtperimeter (above)',\n",
    "#  'Clippedtperimeter (below)',\n",
    "#  'Tperimeter (above)',\n",
    "#  'Tperimeter (below)',\n",
    "#  'Clipped Perimeter (above)',\n",
    "#  'Clipped Perimeter (below)',\n",
    "#  'Form Factor Cell (above)',\n",
    "'Form Factor Cell (below)',\n",
    "'Perimeter Cell (above)',\n",
    "'Perimeter Cell (below)',\n",
    "'Total Area Vac2 Per Cell (above)',\n",
    "'Total Area Vac2 Per Cell (below)',\n",
    "#  'Avg Diam Vac Per Cell (above)',\n",
    "#  'Avg Diam Vac Per Cell (below)',\n",
    "#  'Area All Vac Per Cell (above)',\n",
    "#  'Area All Vac Per Cell (below)',\n",
    "#  '% Area Vac2 Per Cell (above)',\n",
    "#  '% Area Vac2 Per Cell (below)',\n",
    "#  'Count Vacuols Cell (above)',\n",
    "#  'Count Vacuols Cell (below)',\n",
    "#  'Form Factor Vacuols (above)',\n",
    "#  'Form Factor Vacuols (below)',\n",
    "#  'Mito Int Nuc DxA (below)'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lists the colors to be assigned in the plot to each concentration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_colors = {\n",
    "    '0 ug/mL':'black',\n",
    "    #'0.137 ug/mL':'#fee8c8',\n",
    "    #'0.412 ug/mL':'#ff3333',\n",
    "    #'1.235 ug/mL':'#fdbb84',\n",
    "    '3.704 ug/mL':'#fee8c8',#'#990000',\n",
    "    #'11.11 ug/mL':'#fc8d59',\n",
    "    '33.33 ug/mL':'#fdbb84', #'#d7301f',\n",
    "    #'100 ug/mL':'#ef6548',\n",
    "    '300ug/mL':'#e34a33'#'#7f0000'\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "commenting a concentration here removes it from the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concentrations = [\n",
    "    '0 ug/mL',\n",
    "#     '0.412 ug/mL',\n",
    "    '3.704 ug/mL',\n",
    "    '33.33 ug/mL',\n",
    "    '300ug/mL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these functions provide data manipulation necessary to make the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of negative  control\n",
    "NEG_CONTROL = concentrations[0] # i.e. '0 ug/mL'\n",
    "# features and treatments list\n",
    "features = list(thresholds[list(thresholds.keys())[0]].keys())\n",
    "treatments = thresholds[list(thresholds.keys())[0]][features[0]].index.tolist()\n",
    "# remove Triton\n",
    "treatments = [x for x in treatments if 'Triton' not in x]\n",
    "def panel_feature(feat,abovebelow='above'):\n",
    "    '''returns the panel for selected feature.\n",
    "    the panel can be accessed as\n",
    "    panel.loc[experiment,treatment,concentration]\n",
    "    \n",
    "    abovebelow decides wheter the function will return\n",
    "    the percent of cells that went above or below the thresholds.'''\n",
    "    if abovebelow == 'above':\n",
    "        return pd.Panel({n:df for n,df in enumerate([thresholds_above[file][feat] for file in thresholds])})\n",
    "    if abovebelow == 'below':\n",
    "        return pd.Panel({n:df for n,df in enumerate([thresholds_below[file][feat] for file in thresholds])})\n",
    "    \n",
    "def calc_plot_data(panel):\n",
    "    \"\"\"calculates the data that needs to be plotted, for each feature\"\"\"\n",
    "    results = defaultdict(list)\n",
    "    # calculate kruskal-wallis test, and mean/std of altered pop\n",
    "    # vs randomly chosen control well (cn-ppv)\n",
    "    neg_control = panel.loc[:,'PP-CNPPV',NEG_CONTROL].tolist()\n",
    "    for conc in concentrations:\n",
    "        conc_altered = panel.loc[:,TREATMENT,conc].tolist()\n",
    "        if conc == '0 ug/mL': conc_altered = neg_control\n",
    "        try:\n",
    "            results['kruskal'].append(kruskal(neg_control, conc_altered).pvalue)\n",
    "        except ValueError:\n",
    "            results['kruskal'].append('ALLZEROS')\n",
    "        results['mean'].append(np.mean(conc_altered))\n",
    "        results['std'].append(np.std(conc_altered))\n",
    "    return results\n",
    "\n",
    "def plot_altered_pop_pretty(ax):\n",
    "    xaxis = np.array(list(range(len(selected_features)))).astype(int)\n",
    "    ax.set_title(TREATMENT)\n",
    "    for x in xaxis:\n",
    "        ax.axvline(x-.5,linestyle='dashed',linewidth=.2,alpha=.2,color='black')\n",
    "    for n,conc in enumerate(concentrations):\n",
    "        if conc=='control': continue\n",
    "        line = [feature_results[f]['mean'][n] for f in selected_features]\n",
    "        bars = [feature_results[f]['std'][n] for f in selected_features]\n",
    "        ax.errorbar(x=xaxis#+((n-(all_concs/2))/(2*all_concs)\n",
    "                        ,  #uncomment above and different conc's won't all end on the same line\n",
    "                    y=line,\n",
    "                    elinewidth=0.1,\n",
    "                    linewidth=1.5,\n",
    "                    yerr=bars,\n",
    "                    label=conc,\n",
    "                    color=conc_colors[conc],\n",
    "                    alpha=.9,\n",
    "                    capsize=0.5,\n",
    "                    capthick=0.1,\n",
    "                    #fmt='o', # remove this to put back lines in errorbar\n",
    "                    #marker = '_' # https://matplotlib.org/api/markers_api.html\n",
    "                    )\n",
    "    for n,s in enumerate(significances):\n",
    "        ax.plot(1,0,alpha=0,label='{}: p < {} '.format((n+1)*'*',s))\n",
    "    ax.axhline(0,linewidth=.05,color='k', linestyle='dashed',alpha=.3)\n",
    "    ax.set_ylim(top=1.5, bottom=0)\n",
    "    # let's plot the statistics results in the bottom (20% / scale_stat) of the plot     \n",
    "    upper_stat = ax.get_ylim()[0]-0.2\n",
    "    scale_stat = 1.3\n",
    "    stat_plot_height = (ax.get_ylim()[1]-ax.get_ylim()[0])/(scale_stat*3.5)\n",
    "    lower_stat = upper_stat - stat_plot_height+0.1\n",
    "    step = stat_plot_height/all_concs\n",
    "    for n,conc in enumerate(concentrations):\n",
    "        if conc=='control': continue\n",
    "        for xpos,fe in zip(xaxis,selected_features):\n",
    "            signif_level = feature_results[fe]['kruskal'][n]\n",
    "            stringprint = ''\n",
    "            try:\n",
    "                for s in significances:\n",
    "                    if signif_level<=s: stringprint+='*'\n",
    "            except:\n",
    "                if signif_level=='ALLZEROS':\n",
    "                    pass\n",
    "                else:\n",
    "                    raise TypeError\n",
    "            if stringprint:\n",
    "                ax.text(xpos,upper_stat-n*step,stringprint,\n",
    "                       horizontalalignment='center',\n",
    "                       color=conc_colors[conc], fontsize=18)\n",
    "\n",
    "    ax.set_xticks(xaxis)\n",
    "    ax.set_ylabel('Fraction of cell population')\n",
    "    ax.legend(loc='upper right',fontsize = 7, labelspacing=0.2, frameon=1,framealpha=0.5)\n",
    "    ax.set_ylim(lower_stat,ax.get_ylim()[1])\n",
    "\n",
    "counts_by_concentration = defaultdict(dict)\n",
    "for treat in treatments:\n",
    "    for conc in concentrations:\n",
    "        try:\n",
    "            counts_by_concentration[treat][conc] = [counts[file][treat][conc] for file in counts]\n",
    "        except KeyError:\n",
    "            print('err',treat,conc)\n",
    "\n",
    "def kruskal_skiperror(*args):\n",
    "    \"\"\"some features, especially when thresholding below,\n",
    "    give zero cells over threshold.\n",
    "    This would cause error in kruskal\n",
    "    were it not for this error-skip wrapper.\"\"\"\n",
    "    try:\n",
    "        return kruskal(*args).pvalue\n",
    "    except ValueError:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plot dir in case it doesn't exist\n",
    "try: mkdir(figure_path + 'pretty_plots/')\n",
    "except FileExistsError: pass\n",
    "\n",
    "# now looping over treatments and features, compute all data\n",
    "# necessary for the plot\n",
    "for TREATMENT in treatments:\n",
    "    feature_results = dict()\n",
    "    for feat in features:\n",
    "        panel = panel_feature(feat,'above')\n",
    "        feature_results['{} (above)'.format(feat)] = calc_plot_data(panel)\n",
    "        panel = panel_feature(feat,'below')\n",
    "        feature_results['{} (below)'.format(feat)] = calc_plot_data(panel)\n",
    "\n",
    "    negative_control_sample = counts_by_concentration[TREATMENT][NEG_CONTROL]\n",
    "    normalization = np.mean(negative_control_sample)\n",
    "    feature_results['Count'] = {\n",
    "        'std':[np.std(counts_by_concentration[TREATMENT][conc])/normalization\n",
    "               for conc in counts_by_concentration[TREATMENT]],\n",
    "        'mean':[np.mean(counts_by_concentration[TREATMENT][conc])/normalization\n",
    "                for conc in counts_by_concentration[TREATMENT]],\n",
    "        'kruskal':[kruskal_skiperror(negative_control_sample,counts_by_concentration[TREATMENT][conc])\n",
    "                   for conc in counts_by_concentration[TREATMENT]],\n",
    "    }\n",
    "\n",
    "    # signigicance levels to test\n",
    "    significances = [.05,.01,.005]\n",
    "    # just need the number of concentrations\n",
    "    all_concs = len(concentrations)\n",
    "\n",
    "    # plot!\n",
    "    fig = plt.figure(figsize=(3,2.5))\n",
    "    ax = fig.subplots()\n",
    "    plot_altered_pop_pretty(ax)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if save_figures: fig.savefig(figure_path + 'pretty_plots/' + TREATMENT + '.png', dpi=600)\n",
    "    \n",
    "# only show last figure made as an example\n",
    "if show_figures: fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
