{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers\n",
    "This notebook evaluates the accuracy of several classifiers in distinguishing among treatment-induced phenotypes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run notebook_imports\n",
    "%run notebooks/matplotlib_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd party libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from collections import defaultdict \n",
    "import seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\n",
    "import sklearn\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from os import listdir, mkdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import PartialPca\n",
    "from utilities.paths import path\n",
    "from utilities.constants import column_order, index_order, CONC, TREAT\n",
    "from utilities.data_cleaning import label_data, format_column_name, format_dataframe_columns, normalise_data, clean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_classes = True # whether to balance class numbers\n",
    "savefig = True # whether to save figures\n",
    "showfig = True # whether to show figures in the notebook\n",
    "apply_log_transform = False # apply log transformation to the data\n",
    "# how many PCA components to keep. if None, data is not transformed.\n",
    "n_kept_components = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = path.data_classifiers\n",
    "files_list = listdir(data_path)\n",
    "dataset_list=[filename for filename in files_list if filename.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [pd.read_csv(data_path+csv,encoding='utf-8')\n",
    "              for csv in dataset_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing Weighted_Relative_Moment_Inertia\n",
    "# high frequency of nan\n",
    "dataframes = [d.drop(columns=['Weighted_Relative_Moment_Inertia']) for d in dataframes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for filename\n",
    "PCA_string = str(n_kept_components)+'components'\n",
    "param_string = (''\n",
    "               + PCA_string + '-'\n",
    "               + ('balanced' if balance_classes else 'unbalanced')\n",
    "               + '_')\n",
    "plots_dir = path.plots + 'classifiers/'\n",
    "try: mkdir(plots_dir)\n",
    "except FileExistsError: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data cleaning and proper labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_numbers_column(df):\n",
    "    \"\"\"Column 'col' should be called 'number'\"\"\"\n",
    "    cols = df.columns\n",
    "    cols = [colname if colname != 'col' else 'number' for colname in cols]\n",
    "    df.columns = cols\n",
    "    return df\n",
    "dataframes = [rename_numbers_column(d) for d in dataframes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [d.dropna() for d in dataframes]\n",
    "dataframes = [format_dataframe_columns(d) for d in dataframes]\n",
    "dataframes = [label_data(d) for d in dataframes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subsetting\n",
    "keep only some treatments, keep only nanoparticles with 0 concentration (no treatment) and maximum concentration (most nanoparticle effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kept_treatments = [#'FCCP Control', \n",
    "                   'Si-CNPPV','Si-P3', \n",
    "                   'Si-P4',  'PP-CNPPV',    \n",
    "                   'PP-P3',\n",
    "                   'PP-P4', ]\n",
    "kept_concentrations = ['300ug/mL','0 ug/mL', 'control']\n",
    "def subset_data(dataframe):\n",
    "    keep = dataframe[TREAT].isin(kept_treatments) & dataframe[CONC].isin(kept_concentrations)\n",
    "    return keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dataframes = [d.loc[subset_data(d),:] for d in dataframes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## division in classes\n",
    "one class for each nanoparticle type (PP and Si), and a class for no treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relabel_classes(cl):\n",
    "    if cl.startswith('PP'):\n",
    "        return 'PP CPNs'\n",
    "    elif cl.startswith('Si'):\n",
    "        return 'Si CPNs'\n",
    "    else:\n",
    "        return cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_creation(dataframe):\n",
    "    classes = pd.Series(['' for _ in range(dataframe.shape[0])])\n",
    "\n",
    "    for t in kept_treatments:\n",
    "        classes[(dataframe[TREAT] == t).values] = relabel_classes(t)\n",
    "\n",
    "    treated = (dataframe[CONC] == '300ug/mL').values\n",
    "    classes[(dataframe[CONC] == '0 ug/mL').values] = 'Untreated'\n",
    "\n",
    "    dataframe['CLASS'] = classes.tolist()\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dataframes = [class_creation(d) for d in clean_dataframes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop columns that are not measurements, only keep numerical measurements and class column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(dataframe):\n",
    "    for f in ['Row', CONC, TREAT, 'Target']:\n",
    "        try:\n",
    "            dataframe = dataframe.drop(columns=f)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dataframes = [drop_columns(d) for d in clean_dataframes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data normalization\n",
    "z-scoring, optionally logarithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_df(dataframe):\n",
    "    classes = dataframe['CLASS']\n",
    "    #select only numeric data\n",
    "    numeric = dataframe._get_numeric_data()\n",
    "\n",
    "    #apply transformation\n",
    "    numeric = numeric - numeric.mean()\n",
    "    numeric = numeric / numeric.std()\n",
    "\n",
    "    dataframe = numeric\n",
    "    # class information back in\n",
    "    dataframe['CLASS'] = classes.tolist()\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dataframes = [normalise_df(d) for d in clean_dataframes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## aggregate individual datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleandata = pd.concat(clean_dataframes)\n",
    "del clean_dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "otpional logarithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if apply_log_transform:\n",
    "    cleandata = cleandata.apply(np.log)\n",
    "    # if you apply log these features contain numbers <=0, so have to be removed\n",
    "    cleandata = cleandata.drop(['WMOI Cell', 'Moment Cell'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## balanced class counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class counts still unbalanced!\n",
    "class_counts = cleandata['CLASS'].value_counts()\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if balance_classes:\n",
    "    # balance the classes.\n",
    "    max_per_class = min(class_counts)\n",
    "    selection = [] # here we'll put the rows to keep\n",
    "    for klass in class_counts.index: #iterate on all classes\n",
    "        # bool selection of all elements in a class\n",
    "        this_class = cleandata['CLASS'] == klass\n",
    "        # turn into an int selection\n",
    "        this_class_indices = np.where(this_class.values)[0]\n",
    "        # if  you have more elements than `max_per_class` in this class\n",
    "        if this_class.sum() > max_per_class:\n",
    "            # choose randomly `max_per_class` elements\n",
    "            choice = np.random.choice(this_class_indices,size=max_per_class,replace=False)\n",
    "            # add them to the selection to keep\n",
    "            selection += choice.tolist()\n",
    "        else: # otherwise\n",
    "            # keep all elements\n",
    "            selection += this_class_indices.tolist()\n",
    "    # subselect\n",
    "    cleandata = cleandata.iloc[selection,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that it worked\n",
    "class_counts = cleandata['CLASS'].value_counts()\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update classes vector, we'll need it later\n",
    "classes = cleandata['CLASS']\n",
    "#remove classes from dataframe to do dimensionality reduction\n",
    "cleandata = cleandata.drop(columns='CLASS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dimensionality reduction\n",
    "apply a PCA to the data, keep first N components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA = PartialPca.PartialPCA(n_components = cleandata.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA.fit(cleandata.values)\n",
    "results = PCA.transform(cleandata.values).astype(np.dtype('float64'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "look at the loadings of the PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract eigenvectors\n",
    "f = pd.DataFrame(np.vstack([x.astype(float) for x in PCA.eig_vec]).T)\n",
    "f.index = cleandata.columns\n",
    "f_abs=f.abs()\n",
    "# format feature names\n",
    "f_abs.index = [format_column_name(x) for x in f_abs.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "sns.heatmap(f_abs.round(2),  cmap='OrRd', linewidths=2, square=True, annot=True, fmt='0.01f', annot_kws={\"size\": 7},  cbar = False, \n",
    "            cbar_kws={\"shrink\": 0.1}, robust=True)\n",
    "plt.subplots_adjust(\n",
    " left  = 0.25 , right = 0.95\n",
    ")\n",
    "ax.set_xlabel('Principal Components (PC)')\n",
    "ax.set_ylabel('Features')\n",
    "if savefig: fig.savefig(plots_dir+param_string+'PCA_weights.png', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "explained variance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize =(4, 3))\n",
    "var = PCA.explained_variance()\n",
    "ax.scatter(list(range(len(var))), np.cumsum(var), c=var,marker=\"8\",cmap=\"OrRd\",s= 10,   linewidths=0.4, edgecolors=\"Red\")\n",
    "ax.bar(list(range(len(var))), var, color='firebrick', edgecolor='Red')\n",
    "ax.set_title('PCA Explained Variance')\n",
    "ax.set_xlabel('Component #')\n",
    "ax.set_ylabel('Explained variance (%)')\n",
    "fig.tight_layout()\n",
    "if savefig: fig.savefig(plots_dir+param_string+'PCA_explained_variance.png', dpi=600)\n",
    "if showfig: fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_kept_components is not None: # transform data\n",
    "    # take only first `n_kept_components` components\n",
    "    transformed_data = pd.DataFrame(results[:,:n_kept_components])\n",
    "    transformed_data.columns = ['PCA_comp_#'+str(x) for x in transformed_data.columns]\n",
    "else: # don't do PCA at all\n",
    "    transformed_data = cleandata._get_numeric_data()\n",
    "# reinsert classes column\n",
    "transformed_data['CLASS'] = classes.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first 4 components pairplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_kept_components is not None:\n",
    "    plt.close('all')\n",
    "    sns.set_style(\"ticks\", {\"xtick.major.size\": 3, \"ytick.major.size\": 3})\n",
    "    g = sns.pairplot(transformed_data[['PCA_comp_#0', 'PCA_comp_#1', 'PCA_comp_#2', 'PCA_comp_#3','CLASS']],\n",
    "                     hue='CLASS',kind= 'scatter', \n",
    "                     diag_kind='kde', palette=\"inferno\", size=1.4, aspect=1.2, markers = \"o\",  \n",
    "                     plot_kws=dict(s=1, linewidth=0, alpha=0.4, #MarkerEdgeAlpha= 1, edgecolor = 'red'\n",
    "                                  ) ,  \n",
    "                     diag_kws=dict(linewidth=1, shade=True, alpha=0.2, vertical=False, shade_lowest = True))\n",
    "    for ax in g.axes[0,:]:\n",
    "        ax.get_yaxis().set_label_coords(-0.3,0.5)\n",
    "\n",
    "    g.axes[0,0].set_ylabel('PC1')\n",
    "    g.axes[1,0].set_ylabel('PC2')\n",
    "    g.axes[2,0].set_ylabel('PC3')\n",
    "    g.axes[3,0].set_ylabel('PC4')\n",
    "    g.axes[3,0].set_xlabel('PC1')\n",
    "    g.axes[3,1].set_xlabel('PC2')\n",
    "    g.axes[3,2].set_xlabel('PC3')\n",
    "    g.axes[3,3].set_xlabel('PC4')\n",
    "\n",
    "    for ax in g.axes.flatten():\n",
    "        ax.set_xscale(\"symlog\", nonposy='clip')\n",
    "        ax.set_yscale(\"symlog\", nonposy='clip')\n",
    "        ax.tick_params(labelsize=5.5, pad=4,\n",
    "                       zorder =10)\n",
    "\n",
    "    g._legend.set_title(\"Treatments:\")\n",
    "    for lh in g._legend.legendHandles: \n",
    "        lh.set_alpha(1)\n",
    "        lh._sizes = [30] \n",
    "\n",
    "    if savefig: plt.savefig(plots_dir+param_string+'pairplot.png',dpi=600)\n",
    "\n",
    "    if showfig: plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classification\n",
    "let's try a set of simple go-to algorithms: random forest, KNN and MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_classes = set(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle data\n",
    "# dataset = transformed_data.sample(frac=1)\n",
    "transformed_data = transformed_data.dropna()\n",
    "\n",
    "# split into features and target (classes)\n",
    "X = transformed_data._get_numeric_data().values\n",
    "y = transformed_data['CLASS'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import defaultdict\n",
    "from types import SimpleNamespace\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def single_class_accuracy(true_val,pred_val,klass):\n",
    "    \"\"\"tests accuracy for a single class as opposed to overall accuracy\"\"\"\n",
    "    in_class = true_val==klass\n",
    "    correct = true_val[in_class]==pred_val[in_class]\n",
    "    return correct.sum()/correct.size\n",
    "def remove_nans(array):\n",
    "    array = np.array(array)\n",
    "    return array[np.isfinite(array)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list algorithms to use together with parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest = SimpleNamespace()\n",
    "randomforest.model = RandomForestClassifier\n",
    "randomforest.name = 'RandomForest'\n",
    "randomforest.params = {'n_jobs':4,'n_estimators':40}\n",
    "\n",
    "knn = SimpleNamespace()\n",
    "knn.model = KNeighborsClassifier\n",
    "knn.name = 'KNN'\n",
    "knn.params = {'n_jobs':4}\n",
    "\n",
    "mlp = SimpleNamespace()\n",
    "mlp.model = MLPClassifier\n",
    "mlp.name = 'ANN'\n",
    "mlp.params = {'alpha':1}\n",
    "\n",
    "all_models = [randomforest,knn,mlp]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "establish baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies = ['most_frequent', 'stratified', 'prior', 'uniform']\n",
    "baseline_results = dict()\n",
    "for strategy in strategies:\n",
    "    baseline = DummyClassifier(strategy=strategy)\n",
    "    baseline.fit(X,y)\n",
    "    baseline_prediction = baseline.predict(X)\n",
    "    baseline_score = accuracy_score(y, baseline_prediction)\n",
    "    baseline_results[strategy] = baseline_score\n",
    "baseline_max = max(baseline_results.values())\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts_dict = {idx:va for idx,va in zip(class_counts.index,class_counts.values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_kfold(algorithm):\n",
    "    kf = KFold(n_splits=20, shuffle=True)\n",
    "    kf.get_n_splits(X)\n",
    "\n",
    "    scores = defaultdict(list)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        classifier =  algorithm.model(**algorithm.params)\n",
    "        classifier.fit(X[train_index], y[train_index])\n",
    "        model_prediction=classifier.predict(X[test_index])\n",
    "        scores['all'].append(accuracy_score(y[test_index], model_prediction))\n",
    "        for klass in available_classes:\n",
    "            scores[klass].append(single_class_accuracy(y[test_index], model_prediction,klass)) \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_kfold_results(algorithm,scores):\n",
    "    plt.close('all')\n",
    "    fig,ax = plt.subplots(figsize = (6, 4))\n",
    "    bins = np.linspace(0,1,num=50,endpoint=True)\n",
    "    label = 'All cells'\n",
    "    ax.hist(scores['all'], label=label, alpha=.7, bins=bins)\n",
    "    score_mean = np.mean(scores['all'])\n",
    "    ax.axvline(score_mean, label = 'Global accuracy',\n",
    "               color = 'green', alpha=.4)\n",
    "    for klass in available_classes:\n",
    "        label = klass\n",
    "        plt.hist(remove_nans(scores[klass]), label=label, alpha=.2, bins=bins)\n",
    "    ax.axvline(baseline_max, label='Baseline',\n",
    "               color = 'red', alpha=.4)\n",
    "    ax.set_xlim(0,1)\n",
    "    ax.set_ylim(bottom=0)\n",
    "    bbox_inches=\"tight\"\n",
    "    ax.legend(loc=2, frameon =1, fancybox =1, labelspacing = 0.5)\n",
    "    ax.set_xlabel('Accuracy (a.u.)')\n",
    "    ax.set_ylabel('KFolds Count')\n",
    "    ax.set_title('Accuracy single cells classification by treatment on all folds')\n",
    "    fig.tight_layout()\n",
    "    if savefig: fig.savefig(plots_dir+param_string+algorithm.name+'_accuracy.png')\n",
    "    if showfig: fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute test results:\n",
    "for M in all_models:\n",
    "    scores = test_kfold(M)\n",
    "    plot_kfold_results(M,scores)\n",
    "    print(M.name,'accuracy:', np.round(np.mean(scores['all']),3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
